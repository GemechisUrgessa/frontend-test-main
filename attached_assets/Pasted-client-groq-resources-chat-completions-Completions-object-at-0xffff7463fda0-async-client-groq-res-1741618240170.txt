client=<groq.resources.chat.completions.Completions object at 0xffff7463fda0> async_client=<groq.resources.chat.completions.AsyncCompletions object at 0xffff7474cd70> model_name='llama3-70b-8192' temperature=1e-08 model_kwargs={} groq_api_key=SecretStr('**********')
backend-1  | INFO:     172.19.0.1:63424 - "POST /query HTTP/1.1" 500 Internal Server Error
backend-1  | ERROR:    Exception in ASGI application
backend-1  | Traceback (most recent call last):
backend-1  |   File "/usr/local/lib/python3.12/site-packages/uvicorn/protocols/http/h11_impl.py", line 403, in run_asgi
backend-1  |     result = await app(  # type: ignore[func-returns-value]
backend-1  |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
backend-1  |   File "/usr/local/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
backend-1  |     return await self.app(scope, receive, send)
backend-1  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
backend-1  |   File "/usr/local/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
backend-1  |     await super().__call__(scope, receive, send)
backend-1  |   File "/usr/local/lib/python3.12/site-packages/starlette/applications.py", line 113, in __call__
backend-1  |     await self.middleware_stack(scope, receive, send)
backend-1  |   File "/usr/local/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
backend-1  |     raise exc
backend-1  |   File "/usr/local/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
backend-1  |     await self.app(scope, receive, _send)
backend-1  |   File "/usr/local/lib/python3.12/site-packages/starlette/middleware/cors.py", line 93, in __call__
backend-1  |     await self.simple_response(scope, receive, send, request_headers=headers)
backend-1  |   File "/usr/local/lib/python3.12/site-packages/starlette/middleware/cors.py", line 144, in simple_response
backend-1  |     await self.app(scope, receive, send)
backend-1  |   File "/usr/local/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
backend-1  |     await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
backend-1  |   File "/usr/local/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
backend-1  |     raise exc
backend-1  |   File "/usr/local/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
backend-1  |     await app(scope, receive, sender)
backend-1  |   File "/usr/local/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
backend-1  |     await self.middleware_stack(scope, receive, send)
backend-1  |   File "/usr/local/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
backend-1  |     await route.handle(scope, receive, send)
backend-1  |   File "/usr/local/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
backend-1  |     await self.app(scope, receive, send)
backend-1  |   File "/usr/local/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
backend-1  |     await wrap_app_handling_exceptions(app, request)(scope, receive, send)
backend-1  |   File "/usr/local/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
backend-1  |     raise exc
backend-1  |   File "/usr/local/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
backend-1  |     await app(scope, receive, sender)
backend-1  |   File "/usr/local/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
backend-1  |     response = await f(request)
backend-1  |                ^^^^^^^^^^^^^^^^
backend-1  |   File "/usr/local/lib/python3.12/site-packages/fastapi/routing.py", line 291, in app
backend-1  |     solved_result = await solve_dependencies(
backend-1  |                     ^^^^^^^^^^^^^^^^^^^^^^^^^
backend-1  |   File "/usr/local/lib/python3.12/site-packages/fastapi/dependencies/utils.py", line 640, in solve_dependencies
backend-1  |     solved = await run_in_threadpool(call, **solved_result.values)
backend-1  |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
backend-1  |   File "/usr/local/lib/python3.12/site-packages/starlette/concurrency.py", line 39, in run_in_threadpool
backend-1  |     return await anyio.to_thread.run_sync(func, *args)
backend-1  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
backend-1  |   File "/usr/local/lib/python3.12/site-packages/anyio/to_thread.py", line 56, in run_sync
backend-1  |     return await get_async_backend().run_sync_in_worker_thread(
backend-1  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
backend-1  |   File "/usr/local/lib/python3.12/site-packages/anyio/_backends/_asyncio.py", line 2461, in run_sync_in_worker_thread
backend-1  |     return await future
backend-1  |            ^^^^^^^^^^^^
backend-1  |   File "/usr/local/lib/python3.12/site-packages/anyio/_backends/_asyncio.py", line 962, in run
backend-1  |     result = context.run(func, *args)
backend-1  |              ^^^^^^^^^^^^^^^^^^^^^^^^
backend-1  |   File "/app/main.py", line 30, in get_fallback_llm
backend-1  |     llm = LLMFactory.create_llm(llm_type=fallback_llm_config["type"], config=fallback_llm_config)
backend-1  |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
backend-1  |   File "/app/core/llms/llm_factory.py", line 12, in create_llm
backend-1  |     return BedrockLLM(config)
backend-1  |            ^^^^^^^^^^^^^^^^^^
backend-1  |   File "/app/core/llms/bedrock_llm.py", line 32, in __init__
backend-1  |     self._validate_config(config)
backend-1  |   File "/app/core/llms/bedrock_llm.py", line 54, in _validate_config
backend-1  |     raise ValueError(f"{key} is required for Bedrock LLM.")
backend-1  | ValueError: aws_access_key_id is required for Bedrock LLM.


v View in Docker Desktop   o View Config   w Enable Watch